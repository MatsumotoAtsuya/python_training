{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "csv_data = '''A,B,C,D\n",
    "              1.0,2.0,3.0,4.0\n",
    "              5.0,6.0,,8.0\n",
    "              10.0,11.0,12.0,'''\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(thresh = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [\"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values = \"NaN\",strategy = \"mean\",axis = 0)\n",
    "imr = imr.fit(df.values)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "    [\"green\",\"M\",10.01,\"class1\"],\n",
    "    [\"red\",\"L\",13.5,\"class2\"],\n",
    "    [\"blue\",\"XL\",15.4,\"class1\"]\n",
    "])\n",
    "df.columns = [\"color\",\"size\",\"price\",\"classlabel\"]\n",
    "#colulms >> df の　property として設定\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_map = {\"XL\":3,\"L\":2,\"M\":1}\n",
    "df[\"size\"] = df[\"size\"].map(size_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_size_map = {v:k for k ,v in size_map.items()}\n",
    "df[\"size\"].map(inv_size_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class_map = {label:idx for idx,label in enumerate(np.unique(df[\"classlabel\"]))}\n",
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"classlabel\"] = df[\"classlabel\"].map(class_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_class_map = {v:k for k,v in class_map.items()}\n",
    "df[\"classlabel\"] = df[\"classlabel\"].map(inv_class_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder() #LabelEncoder クラスのインスタンスを作る\n",
    "y = class_le.fit_transform(df[\"classlabel\"].values)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"color\",\"size\",\"price\"]].values\n",
    "color_le = LabelEncoder()\n",
    "X[:,0] = color_le.fit_transform(X[:,0])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categorical_features = [0])\n",
    "#OneHotEncoder >> 名義特徴量を0,1 に分ける\n",
    "ohe.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[[\"price\",\"color\",\"size\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[[\"price\",\"color\",\"size\"]])\n",
    "ohe.fit_transform(X).toarray()[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",header = None)\n",
    "df_wine.columns = [\"Class label\",\"Alcohol\",\"Malic acid\",\"Ash\",\"Alcalinity of ash\",\"Magnesium\",\"Totoal phenols\",\"Flabanoids\",\"Nonflavanoid phenols\",\"Proanthocyanins\",\"Color intensity\",\"Hue\",\"OD280/OD315 of diluted wine\",\"Proline\"]\n",
    "print(\"Classlabels\",np.unique(df_wine[\"Class label\"]))\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X,y = df_wine.iloc[:,1:].values,df_wine.iloc[:,0].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=0 ,stratify = y)\n",
    "#stratify >> stratify 中のラベルが　test_data_set,train_data_set それぞれの比率として同じになるようにするもの\n",
    "#ilocについて、ilocはPandasのメソッドの一つ。引数によって指定された行、または列を取り出す。\\\n",
    "#.values はpandas のプロパティの一つ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.fit_transform(X_test)\n",
    "print(X_train_norm[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#標準化　と　正規化\n",
    "ex = np.array([0,1,2,3,4,5])\n",
    "print(\"stndardizet\",(ex - ex.mean()) / ex.std())\n",
    "print(\"normalized\",(ex - ex.min()) / (ex.max() - ex.min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print(X_train_std[:5,:])\n",
    "print(X_test_std[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression(penalty=\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty=\"l1\", C=1.0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print(\"training accuracy:\", lr.score(X_train_std, y_train))\n",
    "print(\"test accuracy: \", lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(1,1,1)\n",
    "colors = [\"blue\",\"green\",\"red\",\"cyan\",\"magenta\",\"yellow\",\"black\",\"pink\",\n",
    "          \"lightgreen\",\"lightblue\",\"gray\",\"indigo\",\"orange\"]\n",
    "weights, params = [], []\n",
    "for c in np.arange(-4.0, 6.0):\n",
    "    lr = LogisticRegression(penalty=\"l1\", C=10.0 ** c, random_state=0)\n",
    "    lr.fit(X_train_std,y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10 ** c)\n",
    "weights = np.array(weights)\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column], label=df_wine.columns[column+1], color=color)\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", linewidth=3)\n",
    "plt.xlim(10 ** (-5), 10 ** 5)\n",
    "plt.ylabel(\"weights coefficients\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.xscale(\"log\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1.38, 1.03), ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SBS():\n",
    "    #future selection & feature extraction\n",
    "    \n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size= test_size\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_train, X_test, y_train, y_test =\\\n",
    "            train_test_split(X, y, test_size=self.test_size, \n",
    "                             random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self._indices = tuple(range(dim))\n",
    "        self._subsets = [self._indices]            \n",
    "        score = self.calc_score(X_train, y_train, X_test, y_test, self._indices)\n",
    "        self._scores = [score]\n",
    "        \n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "            for p in combinations(self._indices, r=dim-1):\n",
    "                score = self.calc_score(X_train, y_train, X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self._indices = subsets[best]\n",
    "            self._subsets.append(self._indices)\n",
    "            dim -= 1\n",
    "            self._scores.append(scores[best])\n",
    "        \n",
    "        self.k_score = self._scores[-1]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[:, self._indices]\n",
    "    \n",
    "    def calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_feat = [len(k) for k in sbs._subsets]\n",
    "plt.plot(k_feat, sbs._scores, marker=\"o\")\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"number of features\")\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#random_state = 0 (X_train　の設定)にすると　まったく違うグラフになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k3 = list(sbs._subsets[10])\n",
    "print(df_wine.columns[1:][k3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std, y_train)\n",
    "print(\"training accuracy: \",knn.score(X_train_std, y_train))\n",
    "print(\"test aiccuracy:\", knn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_std[:, k3], y_train)\n",
    "print(\"training accuracy\", knn.score(X_train_std[:,k3], y_train))\n",
    "print(\"test accuracy\", knn.score(X_test_std[:,k3] , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = df_wine.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"{:0g}),{:<30},{:f}\".format(f+1, feat_labels[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1,X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "#特徴量洗濯のモデル\n",
    "sfm = SelectFromModel(forest, threshold=0.1,prefit=True)\n",
    "X_selected = sfm.transform(X_train)\n",
    "print(\"number of smaples\", X_selected.shape[0])\n",
    "for f in range(X_selected.shape[1]):\n",
    "    print(\"{:f2},{:<30},{f}\".format(f+1, feat_labels[indices[f]], importances[indices[f]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
