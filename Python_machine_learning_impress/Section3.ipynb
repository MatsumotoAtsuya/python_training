{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,[2,3]]\n",
    "y = iris.target\n",
    "print(\"Class labels:\",np.unique(y))\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 1,stratify = y)\n",
    "#stratify >> 層かプリンティング（クラスラベルの比率を一定にする）　…賢い\n",
    "print(\"label counts in y:\",np.bincount(y))\n",
    "print(\"label counts in y_train:\",np.bincount(y_train))\n",
    "print(\"label counts in y_test:\",np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_std = ss.transform(X_train)\n",
    "X_test_std = ss.transform(X_test)\n",
    "# print(X_train_std,X_test_std)\n",
    "#fit と　transform　は全く別のメソッド\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "ppn = Perceptron(n_iter = 40,eta0 = 0.1,random_state = 1)\n",
    "ppn.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print(\"miss_classified:%d\" % (y_test != y_pred).sum())\n",
    "# %で埋め込み数字　sprintf　というらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy: %.2f\" % accuracy_score(y_test,y_pred))\n",
    "print(\"Accuracy: %.2f\" % ppn.score(X_test_std,y_test))\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_decision_regions(X,y,classifier,test_idx = None,resolution = 0.02):\n",
    "    markers = (\"s\",\"x\",\"o\",\"^\",\"v\")\n",
    "    colors = (\"red\",\"blue\",\"lightgreen\",\"gray\",\"cyan\")\n",
    "    cmap =  ListedColormap(colors[:len(np.unique(y))])\n",
    "    x1_min,x1_max = X[:,0].min() - 1 ,X[:,0].max() + 1\n",
    "    x2_min,x2_max = X[:,1].min() - 1 ,X[:,1].max() + 1\n",
    "    xx1,xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),np.arange(x2_min,x2_max,resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1,xx2,Z,alpha = 0.3 ,cmap = cmap)\n",
    "    plt.xlim(xx1.min(),xx1.max())\n",
    "    plt.ylim(xx2.min(),xx2.max())\n",
    "    for idx ,cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = X[y == cl,0] , y = X[y == cl,1] ,alpha = 0.8 , c = colors[idx] ,marker = markers[idx] , label = cl, edgecolor = \"black\" )\n",
    "    if test_idx:\n",
    "        X_test,y_test = X[test_idx,:],y[test_idx]\n",
    "        plt.scatter(X_test[:,0],X_test[:,1],c = \"\",edgecolor = \"black\",alpha = 1,marker = \"o\",s = 100, label = \"test_set\")\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_std = np.vstack((X_train_std,X_test_std))\n",
    "y_combined = np.hstack((y_train,y_test))\n",
    "plot_decision_regions(X = X_combined_std,y = y_combined,classifier = ppn,test_idx = range(105,150))\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.legend(\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "z = np.arange(-7,7,0.1)\n",
    "phi_z = sigmoid(z)\n",
    "plt.plot(z,phi_z)\n",
    "plt.axvline(0.0,color = \"k\") #axvline >> 垂直線\n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.xlabel(\"z\")\n",
    "plt.ylabel(\"$\\phi$\") # phiの記号の記述\n",
    "plt.yticks([0.0,0.5,1.0])\n",
    "ax = plt.gca() #gca >> graphic of axis\n",
    "ax.yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class label が　0 or 1　の場合\n",
    "def cost_1(z):\n",
    "    return -np.log(sigmoid(z))\n",
    "def cost_0(z):\n",
    "    return -np.log(1-sigmoid(z))\n",
    "\n",
    "z = np.arange(-10,10,0.1)\n",
    "phi_z = sigmoid(z)\n",
    "c1 = [cost_1(x) for x in z]\n",
    "plt.plot(phi_z,c1,label = \"J(w) y = 1\")\n",
    "c0 = [cost_0(x) for x in z]\n",
    "plt.plot(phi_z,c0,label = \"J(w) y = -1\")\n",
    "plt.ylim(0.0,5.1)\n",
    "plt.xlim([0,1])\n",
    "plt.xlabel(\"$\\phi$(z)\")\n",
    "plt.ylabel(\"J(w)\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionGD(object):\n",
    "    def __init__(self,eta = 0.05,n_iter = 100,random_state = 1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w = rgen.normal(loc = 0.0,scale = 0.01,size =1+ X.shape[1])\n",
    "        self.gosagun = []\n",
    "        for i in range(self.n_iter):\n",
    "            net_input = self.net_input(X)\n",
    "            output = self.activation(net_input)\n",
    "            errors = (y - output)\n",
    "            self.w[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w[0] += self.eta * errors.sum() #.sum() >> 破壊的メソッド\n",
    "            cost = -y.dot(np.log(output)) - (1-y).dot(np.log(1-output))\n",
    "            self.gosagun.append(cost)\n",
    "        return self\n",
    "            \n",
    "    def net_input(self,X):\n",
    "        return np.dot(X,self.w[1:]) + self.w[0]\n",
    "    \n",
    "    def activation(self,z):\n",
    "        return 1.0 / (1.0 + np.exp(-np.clip(z,-250,250))) #z >250 の時　z -250　に変換する\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.5,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_01_subset = X_train[ (y_train == 0) | (y_train == 1) ]\n",
    "y_train_01_subset = y_train[ (y_train == 0) | (y_train == 1) ]\n",
    "lrgd = LogisticRegressionGD(eta = 0.05,n_iter = 1000,random_state = 1)\n",
    "lrgd.fit(X_train_01_subset,y_train_01_subset)\n",
    "plot_decision_regions(X_train_01_subset,y_train_01_subset,classifier = lrgd)\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C = 100.0,random_state = 1)\n",
    "lr.fit(X_train_std,y_train)\n",
    "plot_decision_regions(X_combined_std,y_combined,classifier = lr,test_idx = range(105,150))\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.legend(loc  = \"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test_std) #probability of 1st,2nd,3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test_std[:10,:]).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_test_std[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights  ,params = [],[]\n",
    "for c in np.arange(-5,5):\n",
    "    lr = LogisticRegression(C = 10.0 ** c,random_state = 1)\n",
    "    lr.fit(X_train_std,y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10.0 ** c)\n",
    "    \n",
    "weights = np.array(weights)\n",
    "plt.plot(params,weights[:,0],label = \"petal length\")\n",
    "plt.plot(params,weights[:,1],label = \"petal width\")\n",
    "plt.ylabel(\"weight coefficient\")\n",
    "plt.xlabel(\"c\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = \"linear\" , C=1.0 ,random_state = 1)\n",
    "svm.fit(X_train_std,y_train)\n",
    "plot_decision_regions(X_combined_std,y_combined,classifier = svm,test_idx = range(105,150))\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "ppn = SGDClassifier(loss = \"perceptron\")\n",
    "lr = SGDClassifier(loss = \"log\")\n",
    "svm = SGDClassifier(loss = \"hinge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "X_xor = np.random.randn(200,2)#random.randn(nand.arrayの形)\n",
    "y_xor = np.logical_xor(X_xor[:,0] > 0 ,X_xor[:,1] > 0)#論理和でTrue　or False を割り当てる\n",
    "y_xor = np.where(y_xor,1,-1) #True >> 1 ,False >> 1の割り当て\n",
    "plt.scatter(X_xor[y_xor == 1,0],X_xor[y_xor ==1,1] ,c = \"b\", marker = \"x\",label = \"1\")\n",
    "plt.scatter(X_xor[y_xor == -1,0],X_xor[y_xor == -1,1],c = \"r\",marker = \"s\",label = \"-1\")\n",
    "plt.xlim([-3,3])\n",
    "plt.ylim([-3,3])\n",
    "plt.legend(loc = \"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm =  SVC(kernel = \"rbf\",random_state = 1 ,gamma = 0.10,C = 10.0)\n",
    "svm.fit(X_xor,y_xor)\n",
    "plot_decision_regions(X_xor,y_xor,classifier = svm)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = \"rbf\",random_state = 1,gamma = 0.2 ,C = 1.0)\n",
    "svm.fit(X_train_std,y_train)\n",
    "plot_decision_regions(X_combined_std,y_combined,classifier = svm,test_idx = range(105,150))\n",
    "plt.xlabel(\"petal lenght\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = \"rbf\" ,random_state = 1,gamma = 100 ,C = 1.0)#rbf >> Radial Basis Function 動型基底カーネル（ガウスカーネル）\n",
    "svm.fit(X_train_std,y_train)\n",
    "plot_decision_regions(X_combined_std,y_combined,classifier = svm,test_idx = range(105,149))\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#decision Tree \n",
    "#informatin gain 1.Gini impurity 2.entropy 3.classification error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def gini(p):\n",
    "    return (p)*(1 - (p)) + (1 - p) * (1 - (1 - p))\n",
    "\n",
    "def entropy(p):#エントロピー\n",
    "    return - p * np.log2(p) - (1 - p) * np.log2((1 - p))\n",
    "\n",
    "def error(p):#分類誤差\n",
    "    return 1 - np.max([p,1 - p])\n",
    "\n",
    "x = np.arange(0.0 ,1.0 ,0.01)\n",
    "ent = [entropy(p) if p != 0 else None for p in x]\n",
    "sc_ent = [e * 0.5 if e else None for e in ent]\n",
    "err = [error(i) for i in x]\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "functions = [ent,sc_ent,gini(x),err]\n",
    "names = [\"entropy\",\"scaled_entropy\",\"Gini Impurity\",\"misclassification error\"]\n",
    "linestyles = [\"-\",\"-\",\"--\",\"-.\"]\n",
    "colors = [\"black\",\"red\",\"green\",\"cyan\"]\n",
    "for i , lab ,ls, c in zip(functions,names,linestyles,colors):\n",
    "    line = ax.plot(x,i,label = lab ,linestyle = ls, color = c, lw =2)\n",
    "ax.legend(loc = \"upper center\",bbox_to_anchor = (0.5,1.15),ncol = 5 ,fancybox = True, shadow = False)\n",
    "ax.axhline(y = 0.5 ,linewidth = 1 ,color = \"k\", linestyle = \"--\")\n",
    "ax.axhline(y = 1.0 ,linewidth = 1, color = \"k\",linestyle = \"--\")\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"Inpurity index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion = \"gini\",max_depth  = 4 ,random_state = 1)\n",
    "tree.fit(X_train,y_train)\n",
    "X_combined = np.vstack((X_train,X_test))\n",
    "y_combined = np.hstack((y_train,y_test))\n",
    "plot_decision_regions(X_combined,y_combined,classifier = tree,test_idx = range(105,150))\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pydotplus import graph_from_dot_data \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dot_data = export_graphviz(tree,filled = True,rounded = True ,class_names = [\"Setosa\",\"Versicolor\",\"Virginica\"],feature_names = [\"petal length\",\"petal width\"],out_file = None)\n",
    "graph = graph_from_dot_data(dot_data)\n",
    "graph.write_png(\"tree.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion = \"gini\",n_estimators = 25,random_state = 1,n_jobs = 2)\n",
    "#n_estimators >> 決定木の数\n",
    "forest.fit(X_train,y_train)\n",
    "plot_decision_regions(X_combined,y_combined,classifier = forest,test_idx = range(105,150)) \n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#minkowski >> ユークリッド距離\n",
    "knn.fit(X_train_std,y_train)\n",
    "plot_decision_regions(X_combined_std,y_combined,classifier = knn,test_idx = range(105,150))\n",
    "plt.xlabel(\"petal length\")\n",
    "plt.ylabel(\"petal width\")\n",
    "plt.legend(\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
